name: mistral-openorca
config_file: |
  name: mistral-openorca
  context_size: 6144
  f16: true
  mmap: true
  threads: 4
  parameters:
    model: huggingface://TheBloke/Mistral-7B-OpenOrca-GGUF/mistral-7b-openorca.Q5_K_S.gguf
    temperature: 0.5
    top_k: 40
    top_p: 0.95
    seed: -1
  template:
    chat_message: |
      <|im_start|>{{if eq .RoleName "assistant"}}assistant{{else if eq .RoleName "system"}}system{{else if eq .RoleName "user"}}user{{end}}
      {{if .Content}}{{.Content}}{{end}}
      <|im_end|>
    chat: |
      {{.Input}}
      <|im_start|>assistant
    completion: |
      {{.Input}}
  stopwords:
  - <|im_end|>
  - <dummy32000>
  
  files:
  - filename: "mistral-7b-openorca.Q5_K_S.gguf"
    sha256: "57f4e4207ba3b6d88f681beb93e3e3a58c6f4e8170fdc5643913d7da24fc59c6"
    uri: "https://huggingface.co/TheBloke/Mistral-7B-OpenOrca-GGUF/resolve/main/mistral-7b-openorca.Q5_K_S.gguf"
  
  usage: |
        curl http://localhost:8080/v1/chat/completions -H "Content-Type: application/json" -d '{
            "model": "mistral-openorca",
            "messages": [{"role": "user", "content": "How are you doing?", "temperature": 0.5}]
        }'
