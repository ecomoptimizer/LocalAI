name: dolphin-mistral
config_file: |
  name: dolphin-mistral
  context_size: 6144
  f16: true
  mmap: true
  threads: 4
  parameters:
    model: huggingface://TheBloke/dolphin-2.6-mistral-7B-GGUF/dolphin-2.6-mistral-7b.Q5_K_M.gguf
    temperature: 0.5
    top_k: 40
    top_p: 0.95
    seed: -1
  template:
    chat_message: |
      <|im_start|>{{if eq .RoleName "assistant"}}assistant{{else if eq .RoleName "system"}}system{{else if eq .RoleName "user"}}user{{end}}
      {{if .Content}}{{.Content}}{{end}}
      <|im_end|>
    chat: |
      {{.Input}}
      <|im_start|>assistant
    completion: |
      {{.Input}}
  stopwords:
  - <|im_end|>
  - <dummy32000>
  
  files:
  - filename: "dolphin-2.6-mistral-7b.Q5_K_M.gguf"
    sha256: "e4ce9eabae27e45131c3d0d99223f133b96257301670073b3aee50f7627e20b2"
    uri: "https://huggingface.co/TheBloke/dolphin-2.6-mistral-7B-GGUF/resolve/main/dolphin-2.6-mistral-7b.Q5_K_M.gguf"
  
  usage: |
        curl http://localhost:8080/v1/chat/completions -H "Content-Type: application/json" -d '{
            "model": "mistral-openorca",
            "messages": [{"role": "user", "content": "How are you doing?", "temperature": 0.5}]
        }'
